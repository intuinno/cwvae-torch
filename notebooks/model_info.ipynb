{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5ca4aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from pathlib import Path\n",
    "import sys  \n",
    "\n",
    "# Get my_package directory path from Notebook\n",
    "parent_dir = str(Path().resolve().parents[0])\n",
    "\n",
    "# Add to sys.path\n",
    "sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a7f742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import distributions as torchd\n",
    "\n",
    "import tools\n",
    "import einops\n",
    "from typing import Union\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7041c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/intuinno/codegit/cwvae-torch'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b698e12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks import Conv3dVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "568920db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Conv3dVAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa10284e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9b96c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12f5d71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv3dVAE(nn.Module):\n",
    "  \n",
    "  def __init__(self, channels_factor=2, \n",
    "               num_conv_layers=2, \n",
    "               act=nn.ELU,\n",
    "               kernels=(4,4,4),\n",
    "               stride=(2,2,2),\n",
    "               input_num_seq=4,\n",
    "               input_width=64,\n",
    "               input_height=64,\n",
    "               input_channels=1,\n",
    "               temp_abs_factor=4):\n",
    "    super(Conv3dVAE, self).__init__()\n",
    "    self._act = act \n",
    "    \n",
    "    enc_layers =[]\n",
    "    in_channels = input_channels\n",
    "    for level in range(num_conv_layers):\n",
    "      out_channels = in_channels * channels_factor\n",
    "      enc_layers.append(nn.Conv3d(in_channels, \n",
    "                                  out_channels,\n",
    "                                  kernels, stride, \n",
    "                                  padding=(1,1,1)\n",
    "                                  ))\n",
    "      if level < num_conv_layers-1:\n",
    "        enc_layers.append(act())\n",
    "      in_channels = out_channels \n",
    "    self.encoder = nn.Sequential(*enc_layers)\n",
    "    \n",
    "    \n",
    "    dec_layers =[]\n",
    "    in_channels = out_channels \n",
    "    for _ in range(num_conv_layers):\n",
    "      out_channels = in_channels // channels_factor \n",
    "      dec_layers.append(nn.ConvTranspose3d(in_channels, \n",
    "                                           out_channels,\n",
    "                                           kernels,\n",
    "                                           stride,\n",
    "                                           padding=(1,1,1),\n",
    "#                                            output_padding=(0,1,1),\n",
    "                                           ))\n",
    "      if level < num_conv_layers-1:\n",
    "        dec_layers.append(act())\n",
    "      in_channels = out_channels\n",
    "    self.decoder = nn.Sequential(*dec_layers)\n",
    "    self._temp_abs_factor = temp_abs_factor\n",
    "    \n",
    "  def forward(self, x):\n",
    "    # Assume x is (b t h w c)\n",
    "    B, T, H, W, C = x.shape\n",
    "    t1 = T // self._temp_abs_factor\n",
    "    x = einops.rearrange(x, 'b t h w c -> b  c t h w') \n",
    "    z = self.encoder(x)\n",
    "    z = torch.clip(z, -0.5, 0.5)\n",
    "    # logits = einops.rearrange(logits, 'b c t h w -> b t h w c')\n",
    "    # dist = torchd.OneHotCategoricalStraightThrough(logits=logits)\n",
    "    # dist = torchd.independent.Independent(dist, 3)\n",
    "    # z = dist.rsample()\n",
    "    # dec_z = einops.rearrange(z, 'b t h w c -> b c t h w')\n",
    "    recon = self.decoder(z)\n",
    "    recon = torch.clip(recon, -0.5, 0.5)\n",
    "    recon = einops.rearrange(recon, 'b c t h w -> b t h w c')\n",
    "    z = einops.rearrange(z, 'b c t h w -> b t h w c')\n",
    "    return recon, z\n",
    "  \n",
    "  def decode(self, emb):\n",
    "    # Assume emb is (b t h w c)\n",
    "    B, T, H, W, C = emb.shape\n",
    "    t2 = C // self._temp_abs_factor\n",
    "    z = einops.rearrange(emb, 'b t h w (c t2) -> (b t) c t2 h w', t2 = t2)\n",
    "    recon = self.decoder(z)\n",
    "    recon = einops.rearrange(recon, '(b t1) c t h w -> b (t1 t) h w c', t1=T)\n",
    "    return recon \n",
    "      \n",
    "    \n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fda69909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/intuinno/anaconda3/envs/cwvae/lib/python3.11/site-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  action_fn=lambda data: sys.getsizeof(data.storage()),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Conv3dVAE                                [10, 4, 64, 64, 1]        --\n",
       "├─Sequential: 1-1                        [10, 16, 1, 16, 16]       --\n",
       "│    └─Conv3d: 2-1                       [10, 4, 2, 32, 32]        260\n",
       "│    └─ELU: 2-2                          [10, 4, 2, 32, 32]        --\n",
       "│    └─Conv3d: 2-3                       [10, 16, 1, 16, 16]       4,112\n",
       "├─Sequential: 1-2                        [10, 1, 4, 64, 64]        --\n",
       "│    └─ConvTranspose3d: 2-4              [10, 4, 2, 32, 32]        4,100\n",
       "│    └─ConvTranspose3d: 2-5              [10, 1, 4, 64, 64]        257\n",
       "==========================================================================================\n",
       "Total params: 8,729\n",
       "Trainable params: 8,729\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 141.93\n",
       "==========================================================================================\n",
       "Input size (MB): 0.66\n",
       "Forward/backward pass size (MB): 2.95\n",
       "Params size (MB): 0.03\n",
       "Estimated Total Size (MB): 3.64\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Conv3dVAE(channels_factor=4)\n",
    "summary(model, input_size=(10,4,64,64,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc64b0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv3dVAE(nn.Module):\n",
    "  \n",
    "  def __init__(self, channels_factor=4, \n",
    "               num_conv_layers=2, \n",
    "               act=nn.ELU,\n",
    "               kernels=(3,3,3),\n",
    "               stride=(2,2,2),\n",
    "               input_num_seq=4,\n",
    "               input_width=64,\n",
    "               input_height=64,\n",
    "               input_channels=1,\n",
    "               temp_abs_factor=4):\n",
    "    super(Conv3dVAE, self).__init__()\n",
    "    self._act = act \n",
    "    \n",
    "    enc_layers =[]\n",
    "    in_channels = input_channels\n",
    "    for level in range(num_conv_layers):\n",
    "      out_channels = in_channels * channels_factor\n",
    "      enc_layers.append(nn.Conv3d(in_channels, \n",
    "                                  out_channels,\n",
    "                                  kernels, stride, \n",
    "                                  padding=(0,1,1)\n",
    "                                  ))\n",
    "      if level < num_conv_layers-1:\n",
    "        enc_layers.append(act())\n",
    "      in_channels = out_channels \n",
    "    enc_layers.append(nn.Tanh())\n",
    "    self.encoder = nn.Sequential(*enc_layers)\n",
    "    \n",
    "    \n",
    "    dec_layers =[]\n",
    "    in_channels = out_channels \n",
    "    for level in range(num_conv_layers):\n",
    "      out_channels = in_channels // channels_factor \n",
    "      dec_layers.append(nn.ConvTranspose3d(in_channels, \n",
    "                                           out_channels,\n",
    "                                           kernels,\n",
    "                                           stride,\n",
    "                                           padding=(0,1,1),\n",
    "                                           output_padding=(0,1,1),\n",
    "                                           ))\n",
    "      if level < num_conv_layers-1:\n",
    "        dec_layers.append(act())\n",
    "      in_channels = out_channels\n",
    "    dec_layers.append(nn.Tanh())\n",
    "    self.decoder = nn.Sequential(*dec_layers)\n",
    "    self._temp_abs_factor = temp_abs_factor\n",
    "    \n",
    "  def forward(self, x):\n",
    "    # Assume x is (b t h w c)\n",
    "    x = einops.rearrange(x, 'b t h w c -> b c t h w' ) \n",
    "    z = self.encoder(x)\n",
    "    recon = self.decoder(z)\n",
    "    recon = einops.rearrange(recon, 'b c t h w -> b t h w c')\n",
    "    z = einops.rearrange(z, 'b c t h w -> b t h w c ')\n",
    "    return recon, z\n",
    "  \n",
    "  def decode(self, emb):\n",
    "    # Assume emb is (b t h w c)\n",
    "    z = einops.rearrange(emb, 'b t h w c -> b c t h w')\n",
    "    recon = self.decoder(z)\n",
    "    recon = einops.rearrange(recon, 'b c t h w -> b t h w c')\n",
    "    return recon \n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45a32bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Conv3dVAE                                [8, 251, 16, 16, 16]      --\n",
       "├─Sequential: 1-1                        [8, 256, 62, 4, 4]        --\n",
       "│    └─Conv3d: 2-1                       [8, 64, 125, 8, 8]        27,712\n",
       "│    └─ELU: 2-2                          [8, 64, 125, 8, 8]        --\n",
       "│    └─Conv3d: 2-3                       [8, 256, 62, 4, 4]        442,624\n",
       "│    └─Tanh: 2-4                         [8, 256, 62, 4, 4]        --\n",
       "├─Sequential: 1-2                        [8, 16, 251, 16, 16]      --\n",
       "│    └─ConvTranspose3d: 2-5              [8, 64, 125, 8, 8]        442,432\n",
       "│    └─ELU: 2-6                          [8, 64, 125, 8, 8]        --\n",
       "│    └─ConvTranspose3d: 2-7              [8, 16, 251, 16, 16]      27,664\n",
       "│    └─Tanh: 2-8                         [8, 16, 251, 16, 16]      --\n",
       "==========================================================================================\n",
       "Total params: 940,432\n",
       "Trainable params: 940,432\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 47.82\n",
       "==========================================================================================\n",
       "Input size (MB): 33.03\n",
       "Forward/backward pass size (MB): 147.59\n",
       "Params size (MB): 3.76\n",
       "Estimated Total Size (MB): 184.38\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Conv3dVAE(channels_factor=4, input_channels=16)\n",
    "summary(model, input_size=(8,252,16,16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83c4d56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv3dVAE(nn.Module):\n",
    "  \n",
    "  def __init__(self, channels_factor=4, \n",
    "               num_conv_layers=4, \n",
    "               act=nn.GELU,\n",
    "               kernels=(3,3,3),\n",
    "               stride=(2,2,2),\n",
    "               input_num_seq=4,\n",
    "               input_width=64,\n",
    "               input_height=64,\n",
    "               input_channels=1,\n",
    "               temp_abs_factor=4):\n",
    "    super(Conv3dVAE, self).__init__()\n",
    "    \n",
    "    c_hid = channels_factor * input_channels \n",
    "    \n",
    "    self.encoder = nn.Sequential(\n",
    "        nn.Conv3d(input_channels, c_hid, kernel_size=3, padding=1, stride=2),  # 64x64 => 32x32\n",
    "        act(),\n",
    "        nn.Conv3d(c_hid, c_hid, kernel_size=3, padding=1),\n",
    "        act(),\n",
    "        nn.Conv3d(c_hid, channels_factor * c_hid, kernel_size=3, padding=1, stride=2),  # 32x32 => 16x16\n",
    "        act(),\n",
    "        nn.Conv3d(channels_factor * c_hid, channels_factor * c_hid, kernel_size=3, padding=1),\n",
    "        nn.Tanh(),\n",
    "        )\n",
    "\n",
    "\n",
    "    self.decoder = nn.Sequential(\n",
    "        nn.ConvTranspose3d(\n",
    "            channels_factor * c_hid, c_hid, kernel_size=3, output_padding=1, padding=1, stride=2\n",
    "        ),  # 16x16 => 32x32\n",
    "        act(),\n",
    "        nn.Conv3d( c_hid,  c_hid, kernel_size=3, padding=1),\n",
    "        act(),\n",
    "        nn.ConvTranspose3d(c_hid, input_channels, kernel_size=3, output_padding=1, padding=1, stride=2),  # 32x32 => 64x64\n",
    "        act(),\n",
    "        nn.Conv3d(input_channels, input_channels, kernel_size=3, padding=1),\n",
    "        nn.Tanh(),  # The input images is scaled between -1 and 1, hence the output has to be bounded as well\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    self._temp_abs_factor = temp_abs_factor\n",
    "    \n",
    "  def forward(self, x):\n",
    "    # Assume x is (b t h w c)\n",
    "    x = einops.rearrange(x, 'b t h w c -> b c t h w' ) \n",
    "    z = self.encoder(x)\n",
    "    recon = self.decoder(z)\n",
    "    recon = einops.rearrange(recon, 'b c t h w -> b t h w c')\n",
    "    z = einops.rearrange(z, 'b c t h w -> b t h w c ')\n",
    "    return recon, z\n",
    "  \n",
    "  def decode(self, emb):\n",
    "    # Assume emb is (b t h w c)\n",
    "    z = einops.rearrange(emb, 'b t h w c -> b c t h w')\n",
    "    recon = self.decoder(z)\n",
    "    recon = einops.rearrange(recon, 'b c t h w -> b t h w c')\n",
    "    return recon \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6b90620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Conv3dVAE                                [8, 1000, 64, 64, 1]      --\n",
       "├─Sequential: 1-1                        [8, 16, 250, 16, 16]      --\n",
       "│    └─Conv3d: 2-1                       [8, 4, 500, 32, 32]       112\n",
       "│    └─GELU: 2-2                         [8, 4, 500, 32, 32]       --\n",
       "│    └─Conv3d: 2-3                       [8, 4, 500, 32, 32]       436\n",
       "│    └─GELU: 2-4                         [8, 4, 500, 32, 32]       --\n",
       "│    └─Conv3d: 2-5                       [8, 16, 250, 16, 16]      1,744\n",
       "│    └─GELU: 2-6                         [8, 16, 250, 16, 16]      --\n",
       "│    └─Conv3d: 2-7                       [8, 16, 250, 16, 16]      6,928\n",
       "│    └─Tanh: 2-8                         [8, 16, 250, 16, 16]      --\n",
       "├─Sequential: 1-2                        [8, 1, 1000, 64, 64]      --\n",
       "│    └─ConvTranspose3d: 2-9              [8, 4, 500, 32, 32]       1,732\n",
       "│    └─GELU: 2-10                        [8, 4, 500, 32, 32]       --\n",
       "│    └─Conv3d: 2-11                      [8, 4, 500, 32, 32]       436\n",
       "│    └─GELU: 2-12                        [8, 4, 500, 32, 32]       --\n",
       "│    └─ConvTranspose3d: 2-13             [8, 1, 1000, 64, 64]      109\n",
       "│    └─GELU: 2-14                        [8, 1, 1000, 64, 64]      --\n",
       "│    └─Conv3d: 2-15                      [8, 1, 1000, 64, 64]      28\n",
       "│    └─Tanh: 2-16                        [8, 1, 1000, 64, 64]      --\n",
       "==========================================================================================\n",
       "Total params: 11,525\n",
       "Trainable params: 11,525\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 20.05\n",
       "==========================================================================================\n",
       "Input size (MB): 131.07\n",
       "Forward/backward pass size (MB): 1179.65\n",
       "Params size (MB): 0.05\n",
       "Estimated Total Size (MB): 1310.77\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Conv3dVAE(channels_factor=4, input_channels=1)\n",
    "summary(model, input_size=(8,1000,64,64,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5d3bce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
