defaults:

  # MODEL
  device: 'cpu'
  exp_name: 'defaults'
  levels: 3
  tmp_abs_factor: 6
  dec_stddev: null
  model_dir_prefix: null
  enc_dense_layers: 3
  enc_dense_hidden_size: 1000
  cell_type: RSSMCell
  cell_stoch_size: null
  cell_deter_size: null
  cell_embed_size: null
  cell_min_stddev: 0.0001
  cell_mean_only: False
  cell_reset_state: False
  use_obs: True
  channels_mult: 1
  precision: 32
  act: "ELU"
  dyn_input_layers: 1
  dyn_output_layers: 1
  dyn_rec_depth: 1
  dyn_shared: False
  dyn_discrete: 0
  dyn_mean_act: 'none'
  dyn_std_act: 'softplus'
  dyn_temp_post:  True 
  dyn_cell: 'gru'
  kl_balance: '0.8'
  kl_scale: '1.0'
  kl_free: '1.0'
  kl_forward: False 
  
  # DATASET
  datadir: data
  dataset: null
  seq_len: null
  eval_seq_len: null
  channels: null

  # TRAINING
  lr: null
  batch_size: 50
  num_epochs: 300
  kl_grad_post_perc: null
  free_nats: null
  beta: null
  clip_grad_norm_by: 100
  eps: 1e-4
  weight_decay: 0.0
  optimizer: "adam"

  # SUMMARIES
  logdir: logs
  open_loop_ctx: 36
  num_val_batches: 1
  save_gifs: True
  save_scalars_every: 1
  save_model_every: 1
  backup_model_every: 30
  eval_every: 1

mmnist_cont:
  # MODEL
  exp_name: "continous"
  levels: 3
  img_size: [64, 64]
  tmp_abs_factor: 6
  dec_stddev: 1.0
  enc_dense_hidden_size: 1000
  cell_type: RSSMCell
  cell_stoch_size: 20
  cell_deter_size: 200
  cell_embed_size: 200

  

  # DATASET
  dataset: mmnist
  seq_len: 100
  eval_seq_len: 1000
  channels: 1
  cnn_depth: 32
  encoder_kernels: [4, 4, 4, 4]
  decoder_kernels: [5, 5, 6, 6]
  decoder_thin: True


  # TRAINING
  lr: 0.0003
  batch_size: 50
  num_epochs: 300

  # SUMMARIES
  open_loop_ctx: 36
  num_val_batches: 1
  save_named_model_every: 5000
  
mmnist_cont_1level:
  # MODEL
  exp_name: "continous_1level"
  levels: 1
  img_size: [64, 64]
  tmp_abs_factor: 6
  dec_stddev: 1.0
  enc_dense_hidden_size: 1000
  cell_type: RSSMCell
  cell_stoch_size: 20
  cell_deter_size: 200
  cell_embed_size: 200

  

  # DATASET
  dataset: mmnist
  seq_len: 100
  eval_seq_len: 1000
  channels: 1
  cnn_depth: 32
  encoder_kernels: [4, 4, 4, 4]
  decoder_kernels: [5, 5, 6, 6]
  decoder_thin: True


  # TRAINING
  lr: 0.0003
  batch_size: 50
  num_epochs: 300

  # SUMMARIES
  open_loop_ctx: 36
  num_val_batches: 1
  save_named_model_every: 5000

mmnist_disc:
  # MODEL
  exp_name: "mmnist_discrete"
  levels: 3
  img_size: [64, 64]
  tmp_abs_factor: 6
  dec_stddev: 1.0
  enc_dense_hidden_size: 1000
  cell_type: RSSMCell
  cell_stoch_size: 32
  cell_deter_size: 600
  cell_embed_size: 600
  dyn_discrete: 32

  precision: 16

  

  # DATASET
  dataset: mmnist
  seq_len: 100
  eval_seq_len: 1000
  channels: 1
  cnn_depth: 32
  encoder_kernels: [4, 4, 4, 4]
  decoder_kernels: [5, 5, 6, 6]
  decoder_thin: True


  # TRAINING
  lr: 0.0003
  batch_size: 128
  num_epochs: 300
  
local_cont:
  # MODEL
  exp_name: "local_cont"
  levels: 3
  img_size: [64, 64]
  tmp_abs_factor: 4
  dec_stddev: 1.0
  enc_dense_hidden_size: 100
  cell_type: RSSMCell
  cell_stoch_size: 32
  cell_deter_size: 100
  cell_embed_size: 100
  dyn_discrete: 0

  precision: 16

  

  # DATASET
  dataset: mmnist
  seq_len: 100
  eval_seq_len: 200
  channels: 1
  cnn_depth: 32
  encoder_kernels: [4, 4, 4, 4]
  decoder_kernels: [5, 5, 6, 6]
  decoder_thin: True


  # TRAINING
  lr: 0.0003
  batch_size: 50
  num_epochs: 300
  

local_discrete:
  # MODEL
  exp_name: "local_discrete"
  levels: 3
  img_size: [64, 64]
  tmp_abs_factor: 4
  dec_stddev: 1.0
  enc_dense_hidden_size: 1000
  cell_type: RSSMCell
  cell_stoch_size: 32
  cell_deter_size: 600
  cell_embed_size: 600
  dyn_discrete: 32

  precision: 32

  

  # DATASET
  dataset: mmnist
  seq_len: 100
  eval_seq_len: 1000
  channels: 1
  cnn_depth: 32
  encoder_kernels: [4, 4, 4, 4]
  decoder_kernels: [5, 5, 6, 6]
  decoder_thin: True


  # TRAINING
  lr: 0.0003
  batch_size: 128
  num_epochs: 300

pretrain:
  # MODEL
  exp_name: "pretrain"
  levels: 3
  img_size: [64, 64]
  tmp_abs_factor: 4
  dec_stddev: 1.0
  enc_dense_hidden_size: 1000
  cell_type: RSSMCell
  cell_stoch_size: 20
  cell_deter_size: 200
  cell_embed_size: 200
  dyn_discrete: 0
  pre_encoder_source_model: 'None'
  # pre_encoder_source_model: 'model/pre_encoder_source_model.pt'
  pre_encoder_model: 'model/pre_encoder.pt'
  # pre_encoder_model: 'None'
  precision: 16

  

  # DATASET
  dataset: mmnist
  seq_len: 100
  eval_seq_len: 1000
  channels: 1
  cnn_depth: 32
  encoder_kernels: [4, 4, 4, 4]
  decoder_kernels: [5, 5, 6, 6]
  decoder_thin: True


  # TRAINING
  lr: 0.0003
  batch_size: 128
  num_epochs: 300
  level1_pretrain: 50
  pre_encoder_num_epochs: 0
  # Summary
  eval_every: 1

mineRL_e2e:
  # MODEL
  exp_name: "mineRL-e2e"
  levels: 3
  img_size: [64, 64]
  tmp_abs_factor: 4
  dec_stddev: 0.4
  enc_dense_hidden_size: 1000
  cell_type: RSSMCell
  cell_stoch_size: 100
  cell_deter_size: 800
  cell_embed_size: 800
  dyn_discrete: 0

  precision: 16

  

  # DATASET
  dataset: minerl
  seq_len: 100
  eval_seq_len: 500
  channels: 3
  cnn_depth: 32
  encoder_kernels: [4, 4, 4, 4]
  decoder_kernels: [5, 5, 6, 6]
  decoder_thin: True


  # TRAINING
  lr: 0.0001
  batch_size: 50
  num_epochs: 600


  # SUMMARIES
  open_loop_ctx: 17
  num_val_batches: 1
  save_named_model_every: 5000

maze_e2e:
  # MODEL
  exp_name: "mineRL-e2e"
  levels: 3
  tmp_abs_factor: 6
  img_size: [64, 64]
  dec_stddev: 0.1
  enc_dense_embed_size: 1000
  cell_type: RSSMCell
  cell_stoch_size: 20
  cell_deter_size: 200
  cell_embed_size: 200
  dyn_discrete: 0

  precision: 16
  # DATASET
  dataset: mazes
  seq_len: 100
  eval_seq_len: 300
  channels: 3
  cnn_depth: 32
  encoder_kernels: [4, 4, 4, 4]
  decoder_kernels: [5, 5, 6, 6]
  decoder_thin: True

  # TRAINING
  lr: 0.0003
  batch_size: 50
  num_epochs: 100

  # SUMMARIES
  open_loop_ctx: 36
  num_val_batches: 1
  save_named_model_every: 5000
